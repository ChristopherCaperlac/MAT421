{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSDU+aSk/rJd241TgoWE/9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CoolWolfy96/MAT421/blob/main/Module_E_Section_3_2%2C_3_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Continuity and Differentiation:** A **limit** of a function describes the behavior of the function as it tends towards a value, x. A function can be called **continuous** when both the limit, or behaviour around x, and its actual value match. A function composed of addition, subtraction, multiplication, and division (but not when denominator is zero) of continuous functions is continuous.\n",
        "\n",
        "Extreme Value Theorem: A **bounded**, continuous function will **always have a maximum and minimum value** that it achieves."
      ],
      "metadata": {
        "id": "laKaTeq_eg3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sympy import *\n",
        "\n",
        "# sympy is a quite useful library in python if working with symbolic/analytical\n",
        "# functions and you need to do operations in calculus\n",
        "\n",
        "x = symbols('x')\n",
        "\n",
        "f = sin(x)/x;\n",
        "limit_f = limit(f, x, 0) # limit of f as x->0\n",
        "\n",
        "print(f)\n",
        "print(limit_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkFDo6pxjk6F",
        "outputId": "fe70f046-777c-4fe7-8fe0-4ec764a6b3ec"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sin(x)/x\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **derivative** is often times defined as the instantaneous rate of change of a function at a value, x. Common derivatives and properties of derivatives (Product and Quotient Rule) can be found, but the limit definition of a derivative can also be used. Derivatives can be expanded to multiple independent variables with **partial derivatives** with respect to each independent variable. The partial derivatives can be grouped into a vector called the **gradient** vector which shows the direction of greatest ascent at a point. On the other hand, **directional derivative** is the ascent going at a certain direction which can be calculated as the dot product of gradient vector and unit direction vector."
      ],
      "metadata": {
        "id": "6hcLr88Yn88r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlzFheJNee5U",
        "outputId": "84af2376-97b7-486b-9f29-36c33afe7613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f: sin(x)\n",
            "Derivative of f: cos(x)\n",
            "At a: 0.0707372016677029\n",
            "\n",
            "f: sin(x)*sin(y)\n",
            "Partial Derivative of f with respect to x: sin(y)*cos(x)\n",
            "At (a,a): 0.0705600040299336\n",
            "\n",
            "Gradient Vector of f: <sin(y)*cos(x), sin(x)*cos(y)>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# using sympy to calculate derivative\n",
        "y = symbols('y')\n",
        "\n",
        "a = 1.5\n",
        "\n",
        "f = sin(x)\n",
        "diff_f = diff(f,x) # derivative of f with respect to x\n",
        "\n",
        "print(\"f: sin(x)\")\n",
        "print(\"Derivative of f: \" + str(diff_f))\n",
        "print(\"At a: \" + str(diff_f.subs(x, a)) + \"\\n\")\n",
        "\n",
        "f = sin(x)*sin(y)\n",
        "diff_fx = diff(f,x) # partial derivative of f with respect to x\n",
        "diff_fy = diff(f,y) # partial derivative of f with respect to y\n",
        "\n",
        "print(\"f: sin(x)*sin(y)\")\n",
        "print(\"Partial Derivative of f with respect to x: \" + str(diff_fx))\n",
        "print(\"At (a,a): \" + str(diff_fx.subs([(x, a),(y, a)])) + \"\\n\")\n",
        "print(\"Gradient Vector of f: \" + \"<\" + str(diff_fx) + \", \" + str(diff_fy) + \">\" + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Taylor's Theorem:** which is more well known in its usage to create the **Taylor's Series** is the polynomial approximation of a function which is differentiable. The important thing to note is that this applies to functions of one variable and functions of multiple variables. The **Lagrange Error Bound** will give an the upper bound on the error of a Taylor's series approximated to a certain degree and point."
      ],
      "metadata": {
        "id": "Pn8o-OqmzZML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x): # taylor series of cos(x) to third degree\n",
        "  return 1 - x**2/2 + x**4/24\n",
        "\n",
        "print(\"Using sympy: \\n\" + str(cos(0.1)))\n",
        "print(\"Using third degree taylor series: \\n\" + str(f(0.1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m5Iq4r69dhK",
        "outputId": "37c5d0e5-961b-4da0-8a53-89106c893882"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using sympy: \n",
            "0.995004165278026\n",
            "Using third degree taylor series: \n",
            "0.9950041666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimization with Gradient Descent/Ascent:** We know that the gradient vector shows the direction of greatest ascent and the direction opposite of the gradient is the direction of greatest descent. From single variable calculus, when the derivative is zero, it is either a minimum, maximum, or inflection point. With more than one variable, it is when the magnitude of the gradient vector is zero. In this case we can create algorithm that gives a local minimum or maximum of a function where we are given or can calculate a gradient (perhaps even numerically).\n",
        "\n",
        "This algorithm (implemented below) essentially picks a point on the domain of the function and calculates the gradient vector. The sum/difference of the point and gradient vector becomes the new point. This is repeated until the gradient is within tolerance/really close to zero. Variations of this algorithm multiply the gradient by a scalar called the learning rate or stop the algorithm after a certain amount of iterations."
      ],
      "metadata": {
        "id": "LkzF45w-3vK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradMagnitude(f, px, py): # returns magnitude of gradient of f\n",
        "  diff_fx = diff(f,x)\n",
        "  diff_fy = diff(f,y)\n",
        "  return sqrt(diff_fx.subs([(x, px),(y, py)])**2 + diff_fy.subs([(x, px),(y, py)])**2)\n",
        "\n",
        "def findMax(f, tol): # find local max of f within tolerance\n",
        "  diff_fx = diff(f,x)\n",
        "  diff_fy = diff(f,y)\n",
        "  px = 0.1\n",
        "  py = 0.1\n",
        "  while gradMagnitude(f, px, py) > tol:\n",
        "    px += diff_fx.subs([(x, px),(y, py)])\n",
        "    py += diff_fy.subs([(x, px),(y, py)])\n",
        "  return (px, py)\n",
        "\n",
        "f = sin(x)*sin(y) # function to be maximized\n",
        "(px, py) = findMax(f, 0.000001)\n",
        "\n",
        "print(px, py) # point where local maximum was achieved\n",
        "print(str(f.subs([(x, px),(y, py)]))) # value of local maximum\n",
        "# note this trig function has an infinite number of local maximum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjT3EX3pIyEM",
        "outputId": "b5f6e6a5-4e0d-4742-fa5c-977a391d9401"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.57079632679490 1.57079632679490\n",
            "1.00000000000000\n"
          ]
        }
      ]
    }
  ]
}