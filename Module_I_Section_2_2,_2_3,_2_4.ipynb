{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwEphHYSeA+iEoj1byMVNa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChristopherCaperlac/MAT421/blob/main/Module_I_Section_2_2%2C_2_3%2C_2_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Probability Axioms:** A sample space is the set of all possible events with an event being an outcome with a probability of occurring.\n",
        "\n",
        "**Conditional Probability:** These events may be independent or dependent as well as mutually exclusive or not. Given prior information about a different event may or may not affect the probability of another event.\n",
        "\n",
        "**Discrete and Continuous Random Variables:** A random variable essentially is a real value that is calculated from a random event in the sample space. The probability of a random variable at a given x is calculated using a PDF while the probability of a random variable less than or equal to a given x is calculated using a CDF. If we are given a set of data or distribution, we can fit it against common distributions and figure out the PDF and CDF. We can also figure out the mean/expected value and variance of a set of data. Common distributions include the normal, poisson, uniform, binomial, and chi-square distribution."
      ],
      "metadata": {
        "id": "fhwt5kV8YYEt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVHjTCxfYIw3",
        "outputId": "d52fadf9-e6f2-42d6-8627-2ed65cd9f45e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "16\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# the built-in python random module allows you to generate random numbers\n",
        "\n",
        "# simulates a bernoulli trial\n",
        "def bernoulli_trial(p):\n",
        "  return 1 if (random.randint(1,1/p) == 1/p) else 0\n",
        "\n",
        "# simulates a binomial distribution\n",
        "def binomial_distribution(n,p):\n",
        "  x = 0\n",
        "  for i in range(n):\n",
        "    x += bernoulli_trial(p)\n",
        "  return x\n",
        "\n",
        "print(bernoulli_trial(0.5))\n",
        "print(binomial_distribution(30,0.5))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Joint Probability Distributions:** We can also extends the PDF and CDF to more than one random variable.\n",
        "\n",
        "**Correlation and Dependence:** Given data of one dependent variable and one or more independent variable, we can compute correlation and dependency of one or more factor on the dependent variable.\n",
        "\n",
        "**Random Samples:** If we take many samples of a population given any distribution, we can create a normal distribution of the sample means which approximate the actual population mean and variance.\n",
        "\n",
        "**Linear Regression:** Given data on one or more independent variable and one dependent variable, we can calculate a line that best fits/correlates the independent variable to the dependent variable using methods like Ordinary Least Squares (OLS)."
      ],
      "metadata": {
        "id": "DbYYet8idEO5"
      }
    }
  ]
}